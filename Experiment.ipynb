{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd015e12cfe0361206d66230a54dc7fb2938cfb5d9b46e860fa44b9fcd523b6b277",
   "display_name": "Python 3.7.10 64-bit ('RL': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Module\n",
    "import numpy as np\n",
    "import copy\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import pytorch_lightning as pl\n",
    "from utils import summarize_prune\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from provided_code.datasource import DataLoaders\n",
    "from pytorch_lightning.metrics import functional as FM\n",
    "from torchvision.datasets import MNIST,CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, BatchSampler\n",
    "from model.cifar10 import  cnn,mlp\n",
    "from utils import summarize_prune,copy_model,get_prune_params,prune_fixed_amount\n",
    "import torch.nn.utils.prune as prune\n"
   ]
  },
  {
   "source": [
    "### DATA PREPARATION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "dataset1 = CIFAR10('./data', train=True,\n",
    "                 transform=transform)\n",
    "dataset2 = CIFAR10('./data', train=False,\n",
    "                 transform=transform)\n",
    "train_loader = DataLoader(dataset1, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(dataset2, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "source": [
    "### MODEL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model = None,\n",
    "        num_classes=10,\n",
    "        batch_size=32,\n",
    "        lr=1e-3,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = FM.accuracy(y_hat, y)\n",
    "        metrics = {\n",
    "            'loss': loss,\n",
    "            'acc': acc}\n",
    "        self.log_dict(metrics)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            params=self.model.parameters(),\n",
    "            lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = FM.accuracy(y_hat, y)\n",
    "        metrics = {\n",
    "            'loss': loss,\n",
    "            'acc': acc}\n",
    "        self.log_dict(metrics)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client():\n",
    "    def __init__(self,args,train_loader,test_loader,idx):\n",
    "        self.args = args\n",
    "        self.model = Model(model = cnn.CNN())\n",
    "        self.test_loader = test_loader\n",
    "        self.train_loader = train_loader\n",
    "        self.idx = idx\n",
    "        self.elapsed_comm_rounds = 0\n",
    "        self.accuracies = np.zeros((args.comm_rounds,self.args.epochs))\n",
    "        self.losses = np.zeros((args.comm_rounds,self.args.epochs))\n",
    "        self.prune_rates = np.zeros(args.comm_rounds)\n",
    "        self.cur_prune_rate = 0.00\n",
    "        self.eita = self.args.eita_hat\n",
    "        self.trainer = pl.Trainer(\n",
    "            gpus = 1,\n",
    "            progress_bar_refresh_rate=60,\n",
    "            max_epochs=self.args.epochs,\n",
    "            fast_dev_run= args.fast_dev_run\n",
    "        )\n",
    "        self.globalModel = copy.deepcopy(self.model)\n",
    "        Client.Prune(self.globalModel.model,prune_rate = 0.0)\n",
    "        self.global_init_model = copy.deepcopy(self.model)\n",
    "        Client.Prune(self.global_init_model.model,prune_rate = 0.0)\n",
    "  \n",
    "\n",
    "    def update(self):\n",
    "        metrics = self.trainer.validate(\n",
    "            model = self.model,\n",
    "            val_dataloaders=self.test_loader,\n",
    "            verbose= True\n",
    "            )\n",
    "        \n",
    "        num_pruned , num_params = summarize_prune(\n",
    "            self.globalModel,name = 'weight')\n",
    "        cur_prune_rate = num_pruned / num_params\n",
    "        if self.cur_prune_rate < self.args.prune_percent:\n",
    "            self.cur_prune_rate = min(self.cur_prune_rate+self.args.prune_step,\n",
    "                                          self.args.prune_percent)\n",
    "            if metrics[0][\"acc\"] > self.eita:\n",
    "                Client.Prune(\n",
    "                    self.globalModel.model,\n",
    "                    prune_rate = self.cur_prune_rate)\n",
    "                self.model = copy_model(\n",
    "                    model = self.global_init_model,\n",
    "                    dataset = self.args.dataset,\n",
    "                    arch = self.args.arch,\n",
    "                    source_buff = dict(self.globalModel.model.named_buffers())\n",
    "                )\n",
    "                self.eita = self.args.eita_hat\n",
    "            else:\n",
    "                self.eita = self.eita*self.args.alpha\n",
    "                self.model = self.globalModel\n",
    "        else:\n",
    "            Client.Prune(\n",
    "                model = self.globalModel.model,\n",
    "                prune_rate = self.args.prune_percent\n",
    "                )\n",
    "            self.model = self.globalModel\n",
    "\n",
    "        self.trainer.fit(\n",
    "            model= self.model,\n",
    "            train_dataloader=self.train_loader,\n",
    "            )\n",
    "        \n",
    "        metrics = self.trainer.validate(\n",
    "            model = self.model,\n",
    "            val_dataloaders =self.test_loader)\n",
    "        \n",
    "        # TODO: LOG MODEL\n",
    "        print(metrics)\n",
    "\n",
    "    @staticmethod\n",
    "    def Prune(model,prune_rate):\n",
    "        params,_,_ = get_prune_params(model)\n",
    "        for param,name in params:\n",
    "            prune.l1_unstructured(\n",
    "                param,\n",
    "                name = name,\n",
    "                amount=prune_rate\n",
    "                )\n",
    "    \n",
    "    def upload(self):\n",
    "        \"\"\"\n",
    "            Upload self.model\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"model\": copy_model(self.model,\n",
    "                                self.args.dataset,\n",
    "                                self.args.arch),\n",
    "            \"acc\": self.eval_score[\"Accuracy\"]\n",
    "        }\n",
    "    \n",
    "    def download(self, globalModel, global_initModel):\n",
    "        \"\"\"\n",
    "            Download global model from server\n",
    "        \"\"\"\n",
    "        self.globalModel = globalModel\n",
    "        self.global_init_model = global_initModel        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "class Args():\n",
    "    arch = \"cnn\"\n",
    "    dataset = \"cifar10\"\n",
    "    epochs = 1\n",
    "    eita_hat = 0.5\n",
    "    alpha = 0.5\n",
    "    prune_percent = 0.8\n",
    "    prune_step = 0.2\n",
    "    comm_rounds = 10\n",
    "    fast_dev_run = False\n",
    "\n",
    "client = Client(\n",
    "    Args(),\n",
    "    idx = 1,\n",
    "    train_loader = train_loader,\n",
    "    test_loader = test_loader\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "                                                              /home/parth/anaconda3/envs/RL/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: you defined a validation_step but have no val_dataloader. Skipping val loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | CNN  | 62.0 K\n",
      "-------------------------------\n",
      "62.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "62.0 K    Total params\n",
      "0.248     Total estimated model params size (MB)\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'acc': 0.10029999911785126, 'loss': 2.3026797771453857}\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 0:  60%|█████▉    | 420/704 [00:04<00:03, 91.64it/s, loss=2.11, v_num=20]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  68%|██████▊   | 480/704 [00:05<00:02, 95.79it/s, loss=2.11, v_num=20]\n",
      "Epoch 0:  77%|███████▋  | 540/704 [00:05<00:01, 100.77it/s, loss=2.11, v_num=20]\n",
      "Epoch 0:  85%|████████▌ | 600/704 [00:05<00:00, 105.96it/s, loss=2.11, v_num=20]\n",
      "Epoch 0:  94%|█████████▍| 660/704 [00:05<00:00, 110.43it/s, loss=2.11, v_num=20]\n",
      "Epoch 0: 100%|██████████| 704/704 [00:06<00:00, 109.96it/s, loss=2.09, v_num=20]\n",
      "Epoch 0: 100%|██████████| 704/704 [00:06<00:00, 109.79it/s, loss=2.09, v_num=20]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  19%|█▉        | 60/313 [00:00<00:01, 139.52it/s]\u001b[A\n",
      "Validating:  38%|███▊      | 120/313 [00:00<00:01, 165.25it/s]\u001b[A\n",
      "Validating:  58%|█████▊    | 180/313 [00:01<00:00, 173.28it/s]\u001b[A\n",
      "Validating:  77%|███████▋  | 240/313 [00:01<00:00, 178.84it/s]\u001b[A\n",
      "Validating:  96%|█████████▌| 300/313 [00:01<00:00, 180.27it/s]\u001b[A\n",
      "                                                              \u001b[A--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'acc': 0.36890000104904175, 'loss': 2.0893971920013428}\n",
      "--------------------------------------------------------------------------------\n",
      "[{'loss': 2.0893971920013428, 'acc': 0.36890000104904175}]\n"
     ]
    }
   ],
   "source": [
    "client.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/313 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  19%|█▉        | 60/313 [00:00<00:01, 155.47it/s]\u001b[A\n",
      "Validating:  38%|███▊      | 120/313 [00:00<00:01, 181.14it/s]\u001b[A\n",
      "Validating:  58%|█████▊    | 180/313 [00:01<00:00, 178.43it/s]\u001b[A\n",
      "Validating:  77%|███████▋  | 240/313 [00:01<00:00, 187.17it/s]\u001b[A\n",
      "Validating:  96%|█████████▌| 300/313 [00:01<00:00, 189.25it/s]\u001b[A\n",
      "                                                              \u001b[A--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'acc': 0.36890000104904175, 'loss': 2.0893971920013428}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'conv1.bias'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-5cc7b976a3d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-82-d4420c4790f5>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0march\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     \u001b[0msource_buff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobalModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 )\n\u001b[1;32m     49\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meita\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meita_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lotteryFL_cell/utils/util.py\u001b[0m in \u001b[0;36mcopy_model\u001b[0;34m(model, dataset, arch, source_buff)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0msource_buffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_buff\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msource_buff\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'conv1.bias'"
     ]
    }
   ],
   "source": [
    "client.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('model.conv1.weight_mask',\n",
       "  tensor([[[[1., 1., 1., 0., 0.],\n",
       "            [1., 0., 1., 1., 1.],\n",
       "            [1., 0., 1., 0., 0.],\n",
       "            [0., 0., 0., 0., 1.],\n",
       "            [1., 0., 0., 0., 0.]],\n",
       "  \n",
       "           [[0., 1., 0., 1., 1.],\n",
       "            [1., 0., 0., 0., 1.],\n",
       "            [1., 0., 1., 0., 0.],\n",
       "            [1., 0., 0., 0., 1.],\n",
       "            [0., 1., 1., 1., 0.]],\n",
       "  \n",
       "           [[0., 1., 1., 1., 1.],\n",
       "            [0., 0., 0., 1., 1.],\n",
       "            [0., 1., 1., 0., 0.],\n",
       "            [1., 0., 0., 1., 0.],\n",
       "            [0., 0., 0., 0., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 0., 1., 1., 1.],\n",
       "            [1., 0., 0., 0., 0.],\n",
       "            [0., 0., 1., 1., 0.],\n",
       "            [0., 1., 1., 1., 1.],\n",
       "            [1., 1., 1., 1., 1.]],\n",
       "  \n",
       "           [[0., 0., 1., 0., 1.],\n",
       "            [0., 0., 1., 0., 0.],\n",
       "            [1., 1., 0., 0., 0.],\n",
       "            [0., 1., 1., 0., 0.],\n",
       "            [0., 1., 1., 1., 0.]],\n",
       "  \n",
       "           [[0., 0., 1., 1., 0.],\n",
       "            [0., 1., 0., 1., 0.],\n",
       "            [0., 1., 1., 0., 0.],\n",
       "            [0., 1., 1., 0., 1.],\n",
       "            [0., 0., 1., 0., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 1., 1., 0., 1.],\n",
       "            [1., 1., 1., 1., 0.],\n",
       "            [1., 1., 0., 1., 1.],\n",
       "            [0., 0., 1., 1., 0.],\n",
       "            [0., 1., 0., 1., 1.]],\n",
       "  \n",
       "           [[1., 0., 0., 0., 0.],\n",
       "            [1., 0., 0., 1., 1.],\n",
       "            [1., 0., 0., 1., 0.],\n",
       "            [0., 1., 0., 0., 1.],\n",
       "            [0., 0., 1., 0., 1.]],\n",
       "  \n",
       "           [[1., 0., 1., 1., 1.],\n",
       "            [1., 0., 0., 0., 0.],\n",
       "            [1., 1., 0., 0., 0.],\n",
       "            [1., 0., 1., 1., 1.],\n",
       "            [1., 0., 1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0., 1., 0.],\n",
       "            [1., 1., 0., 1., 0.],\n",
       "            [0., 0., 1., 1., 1.],\n",
       "            [1., 0., 0., 1., 1.],\n",
       "            [1., 1., 0., 1., 1.]],\n",
       "  \n",
       "           [[0., 0., 1., 1., 1.],\n",
       "            [1., 0., 0., 1., 0.],\n",
       "            [0., 1., 1., 0., 1.],\n",
       "            [0., 1., 0., 1., 1.],\n",
       "            [1., 0., 1., 0., 1.]],\n",
       "  \n",
       "           [[0., 0., 1., 1., 1.],\n",
       "            [1., 0., 0., 0., 0.],\n",
       "            [0., 0., 1., 1., 0.],\n",
       "            [1., 0., 1., 0., 1.],\n",
       "            [0., 0., 0., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1., 0., 1.],\n",
       "            [0., 0., 0., 1., 1.],\n",
       "            [1., 1., 0., 1., 0.],\n",
       "            [1., 1., 1., 0., 0.],\n",
       "            [1., 0., 1., 1., 1.]],\n",
       "  \n",
       "           [[0., 0., 1., 0., 0.],\n",
       "            [1., 0., 1., 0., 1.],\n",
       "            [0., 1., 0., 0., 0.],\n",
       "            [1., 1., 1., 0., 1.],\n",
       "            [1., 0., 0., 0., 0.]],\n",
       "  \n",
       "           [[1., 0., 0., 0., 1.],\n",
       "            [0., 0., 1., 0., 1.],\n",
       "            [1., 1., 1., 0., 0.],\n",
       "            [0., 0., 1., 1., 1.],\n",
       "            [0., 0., 1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 0., 0., 0., 1.],\n",
       "            [0., 0., 0., 0., 1.],\n",
       "            [0., 1., 1., 0., 0.],\n",
       "            [1., 0., 1., 0., 0.],\n",
       "            [0., 0., 0., 1., 1.]],\n",
       "  \n",
       "           [[0., 1., 1., 1., 1.],\n",
       "            [0., 0., 1., 0., 1.],\n",
       "            [1., 0., 0., 1., 1.],\n",
       "            [1., 0., 1., 0., 0.],\n",
       "            [1., 0., 1., 0., 0.]],\n",
       "  \n",
       "           [[1., 0., 1., 1., 1.],\n",
       "            [0., 1., 1., 1., 1.],\n",
       "            [1., 0., 0., 0., 1.],\n",
       "            [0., 1., 0., 1., 0.],\n",
       "            [0., 0., 0., 1., 0.]]]])),\n",
       " ('model.conv2.weight_mask',\n",
       "  tensor([[[[0., 1., 1., 1., 0.],\n",
       "            [1., 1., 0., 0., 1.],\n",
       "            [1., 1., 0., 1., 1.],\n",
       "            [0., 1., 1., 0., 0.],\n",
       "            [0., 0., 1., 1., 1.]],\n",
       "  \n",
       "           [[0., 0., 1., 0., 1.],\n",
       "            [1., 0., 1., 1., 1.],\n",
       "            [0., 0., 0., 1., 1.],\n",
       "            [0., 1., 0., 0., 0.],\n",
       "            [1., 0., 1., 1., 0.]],\n",
       "  \n",
       "           [[1., 1., 1., 0., 1.],\n",
       "            [0., 0., 0., 0., 0.],\n",
       "            [1., 0., 1., 0., 1.],\n",
       "            [1., 0., 1., 1., 0.],\n",
       "            [0., 0., 0., 0., 1.]],\n",
       "  \n",
       "           [[0., 0., 0., 0., 1.],\n",
       "            [1., 0., 0., 1., 0.],\n",
       "            [0., 1., 1., 0., 1.],\n",
       "            [0., 0., 1., 0., 1.],\n",
       "            [0., 0., 0., 0., 1.]],\n",
       "  \n",
       "           [[1., 1., 0., 1., 1.],\n",
       "            [0., 1., 0., 1., 0.],\n",
       "            [0., 0., 0., 0., 0.],\n",
       "            [1., 0., 1., 1., 0.],\n",
       "            [1., 0., 1., 0., 1.]],\n",
       "  \n",
       "           [[0., 0., 0., 1., 1.],\n",
       "            [1., 1., 1., 0., 0.],\n",
       "            [1., 0., 1., 0., 0.],\n",
       "            [0., 0., 0., 1., 0.],\n",
       "            [0., 1., 0., 1., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1., 0., 1.],\n",
       "            [1., 0., 1., 1., 1.],\n",
       "            [0., 0., 1., 0., 0.],\n",
       "            [0., 1., 1., 0., 0.],\n",
       "            [0., 1., 0., 0., 1.]],\n",
       "  \n",
       "           [[0., 1., 1., 1., 1.],\n",
       "            [1., 1., 1., 1., 1.],\n",
       "            [1., 0., 1., 0., 0.],\n",
       "            [1., 0., 0., 0., 1.],\n",
       "            [0., 0., 0., 1., 1.]],\n",
       "  \n",
       "           [[1., 0., 0., 0., 0.],\n",
       "            [1., 0., 1., 0., 0.],\n",
       "            [0., 1., 1., 0., 0.],\n",
       "            [0., 0., 1., 1., 0.],\n",
       "            [0., 0., 1., 0., 1.]],\n",
       "  \n",
       "           [[1., 1., 0., 1., 0.],\n",
       "            [1., 0., 1., 0., 1.],\n",
       "            [0., 0., 0., 0., 1.],\n",
       "            [0., 1., 0., 0., 1.],\n",
       "            [0., 1., 1., 1., 1.]],\n",
       "  \n",
       "           [[0., 0., 0., 0., 1.],\n",
       "            [1., 1., 1., 0., 1.],\n",
       "            [1., 0., 1., 1., 0.],\n",
       "            [1., 0., 1., 1., 1.],\n",
       "            [0., 1., 0., 0., 0.]],\n",
       "  \n",
       "           [[0., 1., 0., 0., 1.],\n",
       "            [0., 0., 0., 0., 1.],\n",
       "            [1., 0., 0., 0., 1.],\n",
       "            [1., 0., 1., 1., 0.],\n",
       "            [1., 1., 1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 1., 1., 0., 1.],\n",
       "            [0., 0., 1., 1., 0.],\n",
       "            [0., 1., 1., 0., 1.],\n",
       "            [0., 0., 0., 0., 0.],\n",
       "            [1., 0., 0., 1., 0.]],\n",
       "  \n",
       "           [[0., 0., 0., 0., 1.],\n",
       "            [0., 0., 1., 0., 0.],\n",
       "            [0., 1., 1., 1., 1.],\n",
       "            [0., 0., 1., 1., 0.],\n",
       "            [1., 1., 0., 0., 0.]],\n",
       "  \n",
       "           [[0., 1., 0., 1., 1.],\n",
       "            [1., 0., 1., 1., 1.],\n",
       "            [0., 1., 0., 0., 0.],\n",
       "            [0., 0., 1., 0., 0.],\n",
       "            [0., 0., 1., 1., 0.]],\n",
       "  \n",
       "           [[1., 0., 0., 1., 0.],\n",
       "            [0., 0., 1., 1., 1.],\n",
       "            [1., 1., 0., 0., 0.],\n",
       "            [0., 1., 0., 0., 1.],\n",
       "            [0., 0., 1., 0., 1.]],\n",
       "  \n",
       "           [[0., 0., 0., 1., 1.],\n",
       "            [0., 0., 1., 1., 1.],\n",
       "            [0., 1., 0., 1., 0.],\n",
       "            [1., 1., 1., 0., 1.],\n",
       "            [1., 1., 0., 0., 1.]],\n",
       "  \n",
       "           [[0., 1., 0., 1., 1.],\n",
       "            [0., 1., 1., 1., 0.],\n",
       "            [0., 1., 1., 1., 0.],\n",
       "            [1., 0., 1., 0., 1.],\n",
       "            [0., 1., 0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 0., 1., 1.],\n",
       "            [0., 1., 0., 1., 0.],\n",
       "            [1., 0., 0., 1., 0.],\n",
       "            [0., 1., 0., 0., 0.],\n",
       "            [1., 1., 0., 1., 1.]],\n",
       "  \n",
       "           [[0., 0., 1., 1., 1.],\n",
       "            [0., 0., 1., 1., 0.],\n",
       "            [0., 1., 0., 1., 0.],\n",
       "            [1., 0., 0., 0., 0.],\n",
       "            [1., 0., 0., 0., 0.]],\n",
       "  \n",
       "           [[1., 0., 0., 0., 1.],\n",
       "            [1., 0., 1., 1., 0.],\n",
       "            [1., 1., 1., 0., 0.],\n",
       "            [1., 1., 0., 1., 0.],\n",
       "            [0., 1., 0., 0., 0.]],\n",
       "  \n",
       "           [[0., 1., 0., 0., 1.],\n",
       "            [0., 0., 1., 0., 1.],\n",
       "            [1., 0., 0., 0., 0.],\n",
       "            [0., 1., 1., 1., 0.],\n",
       "            [0., 1., 1., 0., 1.]],\n",
       "  \n",
       "           [[1., 0., 0., 1., 0.],\n",
       "            [0., 0., 0., 0., 0.],\n",
       "            [0., 0., 1., 0., 0.],\n",
       "            [1., 0., 0., 1., 0.],\n",
       "            [0., 0., 0., 1., 0.]],\n",
       "  \n",
       "           [[0., 0., 0., 1., 1.],\n",
       "            [1., 1., 0., 1., 1.],\n",
       "            [1., 0., 0., 1., 1.],\n",
       "            [0., 0., 1., 1., 0.],\n",
       "            [1., 1., 0., 0., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 1., 1., 0.],\n",
       "            [1., 0., 0., 1., 0.],\n",
       "            [1., 0., 0., 1., 1.],\n",
       "            [0., 1., 1., 0., 1.],\n",
       "            [0., 1., 0., 0., 1.]],\n",
       "  \n",
       "           [[0., 1., 0., 0., 1.],\n",
       "            [1., 0., 1., 0., 1.],\n",
       "            [1., 1., 1., 0., 0.],\n",
       "            [1., 0., 1., 1., 1.],\n",
       "            [1., 1., 0., 0., 0.]],\n",
       "  \n",
       "           [[1., 0., 0., 1., 0.],\n",
       "            [1., 0., 1., 1., 1.],\n",
       "            [0., 0., 1., 0., 1.],\n",
       "            [0., 1., 1., 0., 0.],\n",
       "            [1., 0., 0., 0., 0.]],\n",
       "  \n",
       "           [[0., 0., 0., 1., 0.],\n",
       "            [1., 1., 0., 0., 0.],\n",
       "            [1., 1., 0., 0., 0.],\n",
       "            [0., 1., 0., 1., 1.],\n",
       "            [0., 0., 1., 1., 1.]],\n",
       "  \n",
       "           [[1., 0., 0., 0., 1.],\n",
       "            [0., 0., 0., 0., 0.],\n",
       "            [0., 0., 0., 0., 1.],\n",
       "            [1., 0., 1., 0., 0.],\n",
       "            [0., 1., 1., 0., 0.]],\n",
       "  \n",
       "           [[1., 0., 0., 1., 0.],\n",
       "            [1., 1., 0., 0., 1.],\n",
       "            [1., 1., 0., 0., 1.],\n",
       "            [0., 0., 1., 0., 1.],\n",
       "            [1., 1., 0., 0., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 0., 1., 0.],\n",
       "            [1., 1., 1., 0., 0.],\n",
       "            [0., 1., 1., 0., 1.],\n",
       "            [0., 1., 0., 0., 0.],\n",
       "            [0., 0., 0., 1., 0.]],\n",
       "  \n",
       "           [[1., 1., 0., 0., 0.],\n",
       "            [0., 1., 0., 0., 0.],\n",
       "            [0., 1., 0., 1., 0.],\n",
       "            [0., 1., 1., 1., 0.],\n",
       "            [0., 1., 0., 1., 1.]],\n",
       "  \n",
       "           [[1., 0., 0., 1., 0.],\n",
       "            [0., 1., 0., 1., 0.],\n",
       "            [0., 0., 0., 1., 0.],\n",
       "            [1., 0., 1., 1., 1.],\n",
       "            [1., 0., 0., 0., 1.]],\n",
       "  \n",
       "           [[0., 1., 0., 1., 1.],\n",
       "            [0., 0., 0., 0., 0.],\n",
       "            [0., 1., 0., 1., 0.],\n",
       "            [1., 1., 1., 0., 1.],\n",
       "            [0., 0., 1., 0., 1.]],\n",
       "  \n",
       "           [[0., 0., 1., 1., 0.],\n",
       "            [1., 1., 1., 1., 0.],\n",
       "            [1., 0., 0., 1., 1.],\n",
       "            [1., 0., 0., 0., 1.],\n",
       "            [0., 1., 0., 1., 0.]],\n",
       "  \n",
       "           [[0., 1., 1., 1., 1.],\n",
       "            [1., 0., 1., 0., 1.],\n",
       "            [0., 1., 0., 1., 0.],\n",
       "            [0., 0., 0., 1., 0.],\n",
       "            [0., 1., 1., 1., 1.]]]])),\n",
       " ('model.fc1.weight_mask',\n",
       "  tensor([[1., 0., 1.,  ..., 1., 0., 1.],\n",
       "          [1., 0., 1.,  ..., 1., 0., 0.],\n",
       "          [1., 0., 1.,  ..., 1., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "          [1., 0., 1.,  ..., 1., 1., 0.],\n",
       "          [0., 1., 0.,  ..., 0., 0., 1.]])),\n",
       " ('model.fc2.weight_mask',\n",
       "  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 0., 0.,  ..., 0., 0., 1.],\n",
       "          ...,\n",
       "          [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 1.],\n",
       "          [1., 0., 0.,  ..., 1., 0., 0.]])),\n",
       " ('model.fc3.weight_mask',\n",
       "  tensor([[0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "           0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "           0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "           1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.],\n",
       "          [0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "           1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "           0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
       "           1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
       "           1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "           1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
       "           1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "           1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
       "           0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "           0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "           1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "           0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "           1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.],\n",
       "          [0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "           0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "           0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "           1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "           0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "           0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "           1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "           1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.],\n",
       "          [1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
       "           0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "           0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "           1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.],\n",
       "          [0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "           1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "           1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "           1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "           1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "           1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
       "           1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "           0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "           0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1.]]))]"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "list(model.named_buffers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}