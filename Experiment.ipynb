{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd015e12cfe0361206d66230a54dc7fb2938cfb5d9b46e860fa44b9fcd523b6b277",
   "display_name": "Python 3.7.10 64-bit ('RL': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Module\n",
    "import numpy as np\n",
    "import copy\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import pytorch_lightning as pl\n",
    "from utils import summarize_prune\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from provided_code.datasource import DataLoaders\n",
    "from pytorch_lightning.metrics import functional as FM\n",
    "from torchvision.datasets import MNIST,CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, BatchSampler\n",
    "from model.cifar10 import  cnn,mlp\n",
    "\n"
   ]
  },
  {
   "source": [
    "### DATA PREPARATION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "dataset1 = CIFAR10('./data', train=True,\n",
    "                 transform=transform)\n",
    "dataset2 = CIFAR10('./data', train=False,\n",
    "                 transform=transform)\n",
    "train_loader = DataLoader(dataset1, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(dataset2, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "source": [
    "### MODEL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model = None,\n",
    "        num_classes=10,\n",
    "        batch_size=32,\n",
    "        lr=1e-3,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = FM.accuracy(y_hat, y)\n",
    "        metrics = {\n",
    "            'loss': loss,\n",
    "            'acc': acc}\n",
    "        self.log_dict(metrics)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            params=self.model.parameters(),\n",
    "            lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = FM.accuracy(y_hat, y)\n",
    "        metrics = {\n",
    "            'loss': loss,\n",
    "            'acc': acc}\n",
    "        self.log_dict(metrics)\n",
    "        return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using 1 batch(es).\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | CNN  | 62.0 K\n",
      "-------------------------------\n",
      "62.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "62.0 K    Total params\n",
      "0.248     Total estimated model params size (MB)\n",
      "Epoch 0:  50%|█████     | 1/2 [00:00<00:00,  4.13it/s, loss=2.3, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 2/2 [00:00<00:00,  4.30it/s, loss=2.3, v_num=]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:00<00:00,  3.70it/s, loss=2.3, v_num=]\n"
     ]
    }
   ],
   "source": [
    "model = Model(model = cnn.CNN())\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    fast_dev_run= True)\n",
    "trainer.fit(model=model,train_dataloader=train_loader,val_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method LightningModule.optimizers of Model(\n",
       "  (model): CNN(\n",
       "    (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "    (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "a = Model()\n",
    "a.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}